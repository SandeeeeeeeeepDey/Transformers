# Transformers
Intreagued by using transformer based models like ChatGPT(General Pre-Trained Transformer), I had to learn about what's under the hood.

After learning about basics like gradient descent, logistic regression, backpropagation... I started with RNN, LSTM, RNN with Attention and finally started with Transformers.
Post devouring the delicacy, I am now trying to understand and use the Encoder side as a vision transformer for a practice kaggle competition called "Cassava Leaf detection". Have to be honest, albiet this is a hands-on for me, but I'm using a code that is already written and Im just practicing it without contribution. Commit message to that Notebook will be "ViT Hands-on Practice"

I'll upload the future updates and endaevours.

