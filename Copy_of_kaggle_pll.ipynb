{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1qwzHow6dE8ICmic2YC9Xz9WZKBJi_WgC",
      "authorship_tag": "ABX9TyOe+AXRb4/beWFoREtkwV9j",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SandeeeeeeeeepDey/Transformers/blob/main/Copy_of_kaggle_pll.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch_xla"
      ],
      "metadata": {
        "id": "qDpMAjR8IXuP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install timm"
      ],
      "metadata": {
        "id": "yMHYvS5rIpz_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "337U_vIv785j"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.style.use(\"ggplot\")\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import torch_xla\n",
        "import torch_xla.core.xla_model as xm\n",
        "import torch_xla.distributed.xla_multiprocessing as xmp\n",
        "import torch_xla.distributed.parallel_loader as pl\n",
        "\n",
        "import timm\n",
        "\n",
        "import gc\n",
        "import os\n",
        "import time\n",
        "import random\n",
        "from datetime import datetime\n",
        "\n",
        "from PIL import Image\n",
        "from tqdm.notebook import tqdm\n",
        "from sklearn import model_selection, metrics"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tar -xzvf \"/content/drive/MyDrive/casava/archive.tar.gz\" -C \"/content/input/\""
      ],
      "metadata": {
        "id": "1rOLEEpyiiNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"/content/drive/MyDrive/casava/cassava-leaf-disease-classification.zip\" -d \"/content/input/\""
      ],
      "metadata": {
        "id": "jouKXrunspNK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # For parallelization in TPUs\n",
        "# os.environ[\"XLA_USE_BF16\"] = \"1\"\n",
        "# os.environ[\"XLA_TENSOR_ALLOCATOR_MAXSIZE\"] = \"100000000\""
      ],
      "metadata": {
        "id": "TMdVSlx2XwxH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def seed_everything(seed):\n",
        "    \"\"\"\n",
        "    Seeds basic parameters for reproductibility of results\n",
        "\n",
        "    Arguments:\n",
        "        seed {int} -- Number of the seed\n",
        "    \"\"\"\n",
        "    random.seed(seed)\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "\n",
        "seed_everything(1001)\n"
      ],
      "metadata": {
        "id": "VTfDGv7SYQn8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# general global variables\n",
        "DATA_PATH = \"./input\"\n",
        "TRAIN_PATH = \"./input\"\n",
        "TEST_PATH = \"./input\"\n",
        "MODEL_PATH = (\n",
        "    \"./input\"\n",
        ")\n",
        "\n",
        "# model specific global variables\n",
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 15\n",
        "LR = 1.85e-05\n",
        "GAMMA = 0.7\n",
        "N_EPOCHS = 10"
      ],
      "metadata": {
        "id": "mkWNSTSLZwXP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(os.path.join(DATA_PATH, \"train.csv\"))\n",
        "df.head()"
      ],
      "metadata": {
        "id": "XKt0eHsJaDt8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info\n"
      ],
      "metadata": {
        "id": "RPj_CTgI3qih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.label.value_counts().plot(kind=\"bar\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "id": "MRa-AbAb3r8v",
        "outputId": "0bbd417b-3456-43ec-f99f-ef2cfad3bde1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "metadata": {},
          "execution_count": 50
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df, valid_df = model_selection.train_test_split(df, test_size=0.1,randomstate=42,stratify=df.label.values)"
      ],
      "metadata": {
        "id": "QyF8A-bL5WvE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CassavaDataset(torch.utils.data.Dataset):\n",
        "    \"\"\"\n",
        "    Helper Class to create the pytorch dataset\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, df, data_path=DATA_PATH, mode=\"train\", transforms=None):\n",
        "        super().__init__()\n",
        "        self.df_data = df.values\n",
        "        self.data_path = data_path\n",
        "        self.transforms = transforms\n",
        "        self.mode = mode\n",
        "        self.data_dir = \"train_images\" if mode == \"train\" else \"test_images\"\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df_data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img_name, label = self.df_data[index]\n",
        "        img_path = os.path.join(self.data_path, self.data_dir, img_name)\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "        if self.transforms is not None:\n",
        "            image = self.transforms(img)\n",
        "\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "ldA62Afy3uZR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transforms_train = transforms.Compose(\n",
        "    [\n",
        "        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "        transforms.RandomHorizontalFlip(p=0.3),\n",
        "        transforms.RandomVerticalFlip(p=0.3),\n",
        "        transforms.RandomResizedCrop(IMG_SIZE),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
        "    ]\n",
        ")\n",
        "\n",
        "transforms_valid = transforms.Compose(\n",
        "    [\n",
        "        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "EBtOC_M59NKA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "timm.list_models(\"vit*\")"
      ],
      "metadata": {
        "id": "Uo_2U_Zh3upq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ViTBase16(nn.Module):\n",
        "    def __init__(self, n_classes, pretrained=False):\n",
        "\n",
        "        super(ViTBase16, self).__init__()\n",
        "\n",
        "        self.model = timm.create_model(\"vit_small_patch16_224\", pretrained=False)\n",
        "        if pretrained:\n",
        "            self.model.load_state_dict(torch.load(MODEL_PATH))\n",
        "\n",
        "        self.model.head = nn.Linear(self.model.head.in_features, n_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.model(x)\n",
        "        return x\n",
        "\n",
        "    def train_one_epoch(self, train_loader, criterion, optimizer, device):\n",
        "        # keep track of training loss\n",
        "        epoch_loss = 0.0\n",
        "        epoch_accuracy = 0.0\n",
        "\n",
        "        ###################\n",
        "        # train the model #\n",
        "        ###################\n",
        "        self.model.train()\n",
        "        for i, (data, target) in enumerate(train_loader):\n",
        "            # move tensors to GPU if CUDA is available\n",
        "            if device.type == \"cuda\":\n",
        "                data, target = data.cuda(), target.cuda()\n",
        "            elif device.type == \"xla\":\n",
        "                data = data.to(device, dtype=torch.float32)\n",
        "                target = target.to(device, dtype=torch.int64)\n",
        "\n",
        "            # clear the gradients of all optimized variables\n",
        "            optimizer.zero_grad()\n",
        "            # forward pass: compute predicted outputs by passing inputs to the model\n",
        "            output = self.forward(data)\n",
        "            # calculate the batch loss\n",
        "            loss = criterion(output, target)\n",
        "            # backward pass: compute gradient of the loss with respect to model parameters\n",
        "            loss.backward()\n",
        "            # Calculate Accuracy\n",
        "            accuracy = (output.argmax(dim=1) == target).float().mean()\n",
        "            # update training loss and accuracy\n",
        "            epoch_loss += loss\n",
        "            epoch_accuracy += accuracy\n",
        "\n",
        "            # perform a single optimization step (parameter update)\n",
        "            if device.type == \"xla\":\n",
        "                xm.optimizer_step(optimizer)\n",
        "\n",
        "                if i % 20 == 0:\n",
        "                    xm.master_print(f\"\\tBATCH {i+1}/{len(train_loader)} - LOSS: {loss}\")\n",
        "\n",
        "            else:\n",
        "                optimizer.step()\n",
        "\n",
        "            # if MODEL_PATH is not None:\n",
        "            #   torch.save(self.model.state_dict(), MODEL_PATH)\n",
        "\n",
        "        return epoch_loss / len(train_loader), epoch_accuracy / len(train_loader)\n",
        "\n",
        "    def validate_one_epoch(self, valid_loader, criterion, device):\n",
        "        # keep track of validation loss\n",
        "        valid_loss = 0.0\n",
        "        valid_accuracy = 0.0\n",
        "\n",
        "        ######################\n",
        "        # validate the model #\n",
        "        ######################\n",
        "        self.model.eval()\n",
        "        for data, target in valid_loader:\n",
        "            # move tensors to GPU if CUDA is available\n",
        "            if device.type == \"cuda\":\n",
        "                data, target = data.cuda(), target.cuda()\n",
        "            elif device.type == \"xla\":\n",
        "                data = data.to(device, dtype=torch.float32)\n",
        "                target = target.to(device, dtype=torch.int64)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                # forward pass: compute predicted outputs by passing inputs to the model\n",
        "                output = self.model(data)\n",
        "                # calculate the batch loss\n",
        "                loss = criterion(output, target)\n",
        "                # Calculate Accuracy\n",
        "                accuracy = (output.argmax(dim=1) == target).float().mean()\n",
        "                # update average validation loss and accuracy\n",
        "                valid_loss += loss\n",
        "                valid_accuracy += accuracy\n",
        "\n",
        "        return valid_loss / len(valid_loader), valid_accuracy / len(valid_loader)"
      ],
      "metadata": {
        "id": "i-TIBkDn-Lj-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fit_tpu(\n",
        "    model, epochs, device, criterion, optimizer, train_loader, valid_loader=None\n",
        "):\n",
        "\n",
        "    valid_loss_min = np.Inf  # track change in validation loss\n",
        "\n",
        "    # keeping track of losses as it happen\n",
        "    train_losses = []\n",
        "    valid_losses = []\n",
        "    train_accs = []\n",
        "    valid_accs = []\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        gc.collect()\n",
        "        para_train_loader = pl.ParallelLoader(train_loader, [device])\n",
        "\n",
        "        xm.master_print(f\"{'='*50}\")\n",
        "        xm.master_print(f\"EPOCH {epoch} - TRAINING...\")\n",
        "        train_loss, train_acc = model.train_one_epoch(\n",
        "            para_train_loader.per_device_loader(device), criterion, optimizer, device\n",
        "        )\n",
        "        xm.master_print(\n",
        "            f\"\\n\\t[TRAIN] EPOCH {epoch} - LOSS: {train_loss}, ACCURACY: {train_acc}\\n\"\n",
        "        )\n",
        "        train_losses.append(train_loss)\n",
        "        train_accs.append(train_acc)\n",
        "        gc.collect()\n",
        "\n",
        "        if valid_loader is not None:\n",
        "            gc.collect()\n",
        "            para_valid_loader = pl.ParallelLoader(valid_loader, [device])\n",
        "            xm.master_print(f\"EPOCH {epoch} - VALIDATING...\")\n",
        "            valid_loss, valid_acc = model.validate_one_epoch(\n",
        "                para_valid_loader.per_device_loader(device), criterion, device\n",
        "            )\n",
        "            xm.master_print(f\"\\t[VALID] LOSS: {valid_loss}, ACCURACY: {valid_acc}\\n\")\n",
        "            valid_losses.append(valid_loss)\n",
        "            valid_accs.append(valid_acc)\n",
        "            gc.collect()\n",
        "\n",
        "            # save model if validation loss has decreased\n",
        "            if valid_loss <= valid_loss_min and epoch != 1:\n",
        "                xm.master_print(\n",
        "                    \"Validation loss decreased ({:.4f} --> {:.4f}).  Saving model ...\".format(\n",
        "                        valid_loss_min, valid_loss\n",
        "                    )\n",
        "                )\n",
        "            xm.save(model.state_dict(), 'best_model.pth')\n",
        "\n",
        "            valid_loss_min = valid_loss\n",
        "\n",
        "    return {\n",
        "        \"train_loss\": train_losses,\n",
        "        \"valid_losses\": valid_losses,\n",
        "        \"train_acc\": train_accs,\n",
        "        \"valid_acc\": valid_accs,\n",
        "    }"
      ],
      "metadata": {
        "id": "XD4onk2D-fvf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ViTBase16(n_classes=5, pretrained=False)"
      ],
      "metadata": {
        "id": "-ncx8Bwr-fe-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _run():\n",
        "    train_dataset = CassavaDataset(train_df, transforms=transforms_train)\n",
        "    valid_dataset = CassavaDataset(valid_df, transforms=transforms_valid)\n",
        "\n",
        "    train_sampler = torch.utils.data.distributed.DistributedSampler(\n",
        "        train_dataset,\n",
        "        num_replicas=xm.xrt_world_size(),\n",
        "        rank=xm.get_ordinal(),\n",
        "        shuffle=True,\n",
        "    )\n",
        "\n",
        "    valid_sampler = torch.utils.data.distributed.DistributedSampler(\n",
        "        valid_dataset,\n",
        "        num_replicas=xm.xrt_world_size(),\n",
        "        rank=xm.get_ordinal(),\n",
        "        shuffle=False,\n",
        "    )\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        dataset=train_dataset,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        sampler=train_sampler,\n",
        "        drop_last=True,\n",
        "        num_workers=2,\n",
        "    )\n",
        "\n",
        "    valid_loader = torch.utils.data.DataLoader(\n",
        "        dataset=valid_dataset,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        sampler=valid_sampler,\n",
        "        drop_last=True,\n",
        "        num_workers=2,\n",
        "    )\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    #device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    device = xm.xla_device()\n",
        "    model.to(device)\n",
        "\n",
        "    lr = LR * xm.xrt_world_size()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    xm.master_print(f\"INITIALIZING TRAINING ON {xm.xrt_world_size()} TPU CORES\")\n",
        "    start_time = datetime.now()\n",
        "    xm.master_print(f\"Start Time: {start_time}\")\n",
        "\n",
        "    logs = fit_tpu(\n",
        "        model=model,\n",
        "        epochs=N_EPOCHS,\n",
        "        device=device,\n",
        "        criterion=criterion,\n",
        "        optimizer=optimizer,\n",
        "        train_loader=train_loader,\n",
        "        valid_loader=valid_loader,\n",
        "    )\n",
        "\n",
        "\n",
        "    xm.master_print(f\"Execution time: {datetime.now() - start_time}\")\n",
        "\n",
        "    xm.master_print(\"Saving Model\")\n",
        "    xm.save(\n",
        "        model.state_dict(), f'model_5e_{datetime.now().strftime(\"%Y%m%d-%H%M\")}.pth'\n",
        "    )"
      ],
      "metadata": {
        "id": "7G1XDpn5-fZz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Start training processes\n",
        "def _mp_fn(rank, flags):\n",
        "    torch.set_default_tensor_type(\"torch.FloatTensor\")\n",
        "    a = _run()\n",
        "\n",
        "\n",
        "# _run()\n",
        "FLAGS = {}\n",
        "xmp.spawn(_mp_fn, args=(FLAGS,), nprocs=2, start_method=\"fork\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C8WYvPNl-fRx",
        "outputId": "9e2656ff-83f0-4359-a9c3-1dab0c2fac56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Unsupported nprocs (2), ignoring...\n",
            "/usr/local/lib/python3.10/dist-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:451.)\n",
            "  _C._set_default_tensor_type(t)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INITIALIZING TRAINING ON 1 TPU CORES\n",
            "Start Time: 2024-01-25 08:35:32.006133\n",
            "==================================================\n",
            "EPOCH 1 - TRAINING...\n",
            "\tBATCH 1/1283 - LOSS: 2.015625\n",
            "\tBATCH 21/1283 - LOSS: 1.5546875\n",
            "\tBATCH 41/1283 - LOSS: 1.2734375\n",
            "\tBATCH 61/1283 - LOSS: 0.953125\n",
            "\tBATCH 81/1283 - LOSS: 1.1640625\n",
            "\tBATCH 101/1283 - LOSS: 1.296875\n"
          ]
        }
      ]
    }
  ]
}